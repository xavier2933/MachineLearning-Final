{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ry5YNVtxNgaQ",
        "outputId": "cd359491-3e4e-4f8a-d5e9-b60f2a766958"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running model with top 5 features\n",
            "Selected features: ['filler%', 'speaker_balance', 'word_length_2', 'word_length_6', '8+ words']\n",
            "Average r: 0.2398\n",
            "Average RE: 0.0771\n",
            "\n",
            "Group: Gender\n",
            "('Female',): r = 0.2958, RE = 0.0763\n",
            "('Male',): r = 0.1586, RE = 0.0781\n",
            "\n",
            "Group: Race\n",
            "('African American',): r = 0.2273, RE = 0.0736\n",
            "('Hispanic',): r = 0.2106, RE = 0.0872\n",
            "('White',): r = 0.2869, RE = 0.0685\n",
            "\n",
            "Group: Gender x Race\n",
            "('Female', 'African American'): r = 0.1149, RE = 0.0744\n",
            "('Female', 'Hispanic'): r = 0.3485, RE = 0.0819\n",
            "('Female', 'White'): r = 0.3502, RE = 0.0729\n",
            "('Male', 'African American'): r = 0.3737, RE = 0.0720\n",
            "('Male', 'Hispanic'): r = 0.0843, RE = 0.0919\n",
            "('Male', 'White'): r = 0.1938, RE = 0.0624\n",
            "\n",
            "Worst performing group: ('Male', 'Hispanic') with RE = 0.0919\n",
            "\n",
            "Running model with top 10 features\n",
            "Selected features: ['filler%', 'speaker_balance', 'total_word_count', 'word_length_2', 'word_length_3', 'word_length_4', 'word_length_6', 'word_length_7', '8+ words', 'maximum_sentence_sentiment']\n",
            "Average r: 0.1919\n",
            "Average RE: 0.0770\n",
            "\n",
            "Group: Gender\n",
            "('Female',): r = 0.2321, RE = 0.0760\n",
            "('Male',): r = 0.1346, RE = 0.0783\n",
            "\n",
            "Group: Race\n",
            "('African American',): r = 0.1633, RE = 0.0781\n",
            "('Hispanic',): r = 0.1495, RE = 0.0874\n",
            "('White',): r = 0.2837, RE = 0.0646\n",
            "\n",
            "Group: Gender x Race\n",
            "('Female', 'African American'): r = 0.0389, RE = 0.0786\n",
            "('Female', 'Hispanic'): r = 0.2740, RE = 0.0828\n",
            "('Female', 'White'): r = 0.3555, RE = 0.0676\n",
            "('Male', 'African American'): r = 0.2714, RE = 0.0772\n",
            "('Male', 'Hispanic'): r = 0.0662, RE = 0.0916\n",
            "('Male', 'White'): r = 0.2290, RE = 0.0604\n",
            "\n",
            "Worst performing group: ('Male', 'Hispanic') with RE = 0.0916\n",
            "\n",
            "Running model with top all features\n",
            "Selected features: ['filler%', 'speaker_balance', 'total_word_count', 'word_length_2', 'word_length_3', 'word_length_4', 'word_length_5', 'word_length_6', 'word_length_7', '8+ words', 'average_sentence_sentiment', 'minimum_sentence_sentiment', 'maximum_sentence_sentiment']\n",
            "Average r: 0.1703\n",
            "Average RE: 0.0778\n",
            "\n",
            "Group: Gender\n",
            "('Female',): r = 0.1792, RE = 0.0797\n",
            "('Male',): r = 0.1575, RE = 0.0754\n",
            "\n",
            "Group: Race\n",
            "('African American',): r = 0.0873, RE = 0.0781\n",
            "('Hispanic',): r = 0.1344, RE = 0.0887\n",
            "('White',): r = 0.2886, RE = 0.0657\n",
            "\n",
            "Group: Gender x Race\n",
            "('Female', 'African American'): r = -0.0688, RE = 0.0843\n",
            "('Female', 'Hispanic'): r = 0.1935, RE = 0.0885\n",
            "('Female', 'White'): r = 0.3822, RE = 0.0679\n",
            "('Male', 'African American'): r = 0.2875, RE = 0.0655\n",
            "('Male', 'Hispanic'): r = 0.1289, RE = 0.0888\n",
            "('Male', 'White'): r = 0.1763, RE = 0.0626\n",
            "\n",
            "Worst performing group: ('Male', 'Hispanic') with RE = 0.0888\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.feature_selection import SelectKBest, f_regression, f_classif\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# Load and merge data\n",
        "features = pd.read_csv(\"features.csv\")\n",
        "scores = pd.read_csv(\"scores.csv\")\n",
        "data = pd.merge(features, scores, left_on=\"id\", right_on=\"Participant\")\n",
        "\n",
        "# Simulated demographic columns for testing\n",
        "np.random.seed(42)\n",
        "n = len(data)\n",
        "data[\"Gender\"] = np.random.choice([\"Male\", \"Female\"], size=n)\n",
        "data[\"Race\"] = np.random.choice([\"White\", \"African American\", \"Hispanic\"], size=n)\n",
        "\n",
        "# Used 'Overall' as a proxy for PHQ-8 score\n",
        "X = data.drop(columns=[\"id\", \"Participant\", \"Overall\", \"Excited\", \"Gender\", \"Race\"])\n",
        "y = data[\"Overall\"].values\n",
        "\n",
        "# Standardized the numeric features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "# Selected top-k features using f_regression\n",
        "def select_top_k(X, y, k):\n",
        "    selector = SelectKBest(score_func=f_regression, k=k)\n",
        "    X_new = selector.fit_transform(X, y)\n",
        "    selected_columns = X.columns[selector.get_support()]\n",
        "    return pd.DataFrame(X_new, columns=selected_columns), selected_columns.tolist()\n",
        "\n",
        "# Evaluated performance metrics for demographic subgroups\n",
        "def evaluate_by_group(data, preds, true):\n",
        "    data = data.copy()\n",
        "    data[\"preds\"] = preds\n",
        "    data[\"true\"] = true\n",
        "    for group_cols in [[\"Gender\"], [\"Race\"], [\"Gender\", \"Race\"]]:\n",
        "        print(\"\\nGroup:\", \" x \".join(group_cols))\n",
        "        for group, group_df in data.groupby(group_cols):\n",
        "            r = pearsonr(group_df[\"preds\"], group_df[\"true\"])[0]\n",
        "            re = np.mean(np.abs(group_df[\"preds\"] - group_df[\"true\"]) / np.max(true))\n",
        "            print(f\"{group}: r = {r:.4f}, RE = {re:.4f}\")\n",
        "\n",
        "# Found the group with the highest relative error\n",
        "def find_worst_group(data, preds, true):\n",
        "    data = data.copy()\n",
        "    data[\"preds\"] = preds\n",
        "    data[\"true\"] = true\n",
        "    worst_group = None\n",
        "    worst_re = -1\n",
        "    for group, group_df in data.groupby([\"Gender\", \"Race\"]):\n",
        "        re = np.mean(np.abs(group_df[\"preds\"] - group_df[\"true\"]) / np.max(true))\n",
        "        if re > worst_re:\n",
        "            worst_re = re\n",
        "            worst_group = group\n",
        "    print(\"\\nWorst performing group:\", worst_group, \"with RE =\", round(worst_re, 4))\n",
        "\n",
        "# Ran model with multiple k values\n",
        "for k in [5, 10, 'all']:\n",
        "    print(f\"\\nRunning model with top {k} features\")\n",
        "    X_k, selected_features = select_top_k(X_scaled_df, y, k=k)\n",
        "    print(\"Selected features:\", selected_features)\n",
        "\n",
        "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    all_preds = np.zeros_like(y)\n",
        "\n",
        "    for train_idx, test_idx in kf.split(X_k):\n",
        "        X_train, X_test = X_k.iloc[train_idx], X_k.iloc[test_idx]\n",
        "        y_train = y[train_idx]\n",
        "        model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "        model.fit(X_train, y_train)\n",
        "        all_preds[test_idx] = model.predict(X_test)\n",
        "\n",
        "    avg_r = pearsonr(all_preds, y)[0]\n",
        "    avg_re = np.mean(np.abs(all_preds - y) / np.max(y))\n",
        "    print(f\"Average r: {avg_r:.4f}\")\n",
        "    print(f\"Average RE: {avg_re:.4f}\")\n",
        "\n",
        "    evaluate_by_group(data, all_preds, y)\n",
        "    find_worst_group(data, all_preds, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Convert to tensors\n",
        "X_tensor = torch.tensor(X_scaled, dtype=torch.float32)\n",
        "y_tensor = torch.tensor(y, dtype=torch.float32).view(-1, 1)\n",
        "\n",
        "# Defined a basic feedforward neural network\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(64, 32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
        "nn_preds = np.zeros_like(y)\n",
        "\n",
        "# Ran 5-fold CV with the model\n",
        "for train_idx, test_idx in kf.split(X_tensor):\n",
        "    X_tr, X_te = X_tensor[train_idx], X_tensor[test_idx]\n",
        "    y_tr, y_te = y_tensor[train_idx], y_tensor[test_idx]\n",
        "\n",
        "    model = SimpleNN(X_tensor.shape[1])\n",
        "    opt = optim.Adam(model.parameters(), lr=0.001)\n",
        "    loss_fn = nn.MSELoss()\n",
        "\n",
        "    for _ in range(1000):  # Reduced training epochs\n",
        "        model.train()\n",
        "        opt.zero_grad()\n",
        "        out = model(X_tr)\n",
        "        loss = loss_fn(out, y_tr)\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        nn_preds[test_idx] = model(X_te).squeeze().numpy()\n",
        "\n",
        "# Evaluated performance\n",
        "r = pearsonr(nn_preds, y)[0]\n",
        "re = np.mean(np.abs(nn_preds - y) / np.max(y))\n",
        "print(f\"\\nDeep Learning Model — Avg r = {r:.4f}, Avg RE = {re:.4f}\")\n",
        "\n",
        "evaluate_by_group(data, nn_preds, y)\n",
        "find_worst_group(data, nn_preds, y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3v6IjmXwPNHo",
        "outputId": "d036f332-4b34-4351-86c7-4a2408e21eb7"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Deep Learning Model — Avg r = 0.1138, Avg RE = 0.1035\n",
            "\n",
            "Group: Gender\n",
            "('Female',): r = 0.1090, RE = 0.1061\n",
            "('Male',): r = 0.0996, RE = 0.1002\n",
            "\n",
            "Group: Race\n",
            "('African American',): r = 0.3119, RE = 0.0839\n",
            "('Hispanic',): r = 0.0531, RE = 0.1203\n",
            "('White',): r = 0.0815, RE = 0.0997\n",
            "\n",
            "Group: Gender x Race\n",
            "('Female', 'African American'): r = 0.1776, RE = 0.0826\n",
            "('Female', 'Hispanic'): r = 0.0992, RE = 0.1349\n",
            "('Female', 'White'): r = 0.1607, RE = 0.1005\n",
            "('Male', 'African American'): r = 0.4614, RE = 0.0864\n",
            "('Male', 'Hispanic'): r = -0.0412, RE = 0.1073\n",
            "('Male', 'White'): r = 0.1938, RE = 0.0985\n",
            "\n",
            "Worst performing group: ('Female', 'Hispanic') with RE = 0.1349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In my analysis, I used both a Random Forest (tree-based) model and a simple feedforward neural network (deep learning) to estimate depression severity based on behavioral features. The Random Forest model consistently performed better than the neural network across different settings — it gave higher Pearson correlation values and lower relative errors. Based on the results, I found that the tree-based model was more effective for this dataset, probably because it handles smaller datasets and nonlinear patterns more reliably without needing much fine-tuning.\n",
        "\n"
      ],
      "metadata": {
        "id": "BCiU5WjLKb4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import f_classif, f_regression\n",
        "\n",
        "def top_feats(X, y, k=10, func=f_regression):\n",
        "    sel = SelectKBest(score_func=func, k=k)\n",
        "    sel.fit(X, y)\n",
        "    return X.columns[sel.get_support()].tolist()\n",
        "\n",
        "phq_feats = top_feats(X_scaled_df, data[\"Overall\"], k=10, func=f_regression)\n",
        "gender_feats = top_feats(X_scaled_df, data[\"Gender\"], k=10, func=f_classif)\n",
        "race_feats = top_feats(X_scaled_df, data[\"Race\"], k=10, func=f_classif)\n",
        "\n",
        "print(\"\\nTop features for PHQ-8 (Overall):\", phq_feats)\n",
        "print(\"Top features for Gender:\", gender_feats)\n",
        "print(\"Top features for Race:\", race_feats)\n",
        "\n",
        "print(\"\\nOverlap with Gender:\", set(phq_feats) & set(gender_feats))\n",
        "print(\"Overlap with Race:\", set(phq_feats) & set(race_feats))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hzRbEf-9QM_9",
        "outputId": "d8c3f1ec-0881-4014-a9a2-18768403c110"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top features for PHQ-8 (Overall): ['filler%', 'speaker_balance', 'total_word_count', 'word_length_2', 'word_length_3', 'word_length_4', 'word_length_6', 'word_length_7', '8+ words', 'maximum_sentence_sentiment']\n",
            "Top features for Gender: ['filler%', 'speaker_balance', 'total_word_count', 'word_length_2', 'word_length_4', 'word_length_5', 'word_length_6', '8+ words', 'average_sentence_sentiment', 'maximum_sentence_sentiment']\n",
            "Top features for Race: ['speaker_balance', 'total_word_count', 'word_length_2', 'word_length_4', 'word_length_5', 'word_length_6', 'word_length_7', '8+ words', 'minimum_sentence_sentiment', 'maximum_sentence_sentiment']\n",
            "\n",
            "Overlap with Gender: {'total_word_count', 'speaker_balance', 'word_length_4', 'word_length_6', 'filler%', '8+ words', 'word_length_2', 'maximum_sentence_sentiment'}\n",
            "Overlap with Race: {'total_word_count', 'speaker_balance', 'word_length_4', 'word_length_6', '8+ words', 'word_length_2', 'word_length_7', 'maximum_sentence_sentiment'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUbfdZjWRT2j"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}